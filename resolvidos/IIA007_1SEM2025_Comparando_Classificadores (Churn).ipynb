{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb45d80",
   "metadata": {},
   "source": [
    "# **Classificadores: Regressão Logística, Árvore de Decisão e Naive Bayes**\n",
    "\n",
    "## Disciplina: Inteligência Artificial e Aplicações\n",
    "## FATEC Ferraz de Vasconcelos\n",
    "### Professora: Ana Rosa C. Tonão\n",
    "#### Data: 23/06/2025\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452580ff",
   "metadata": {},
   "source": [
    "# **Comparação de Modelos de Classificação para Previsão de Churn**\n",
    "\n",
    "**Objetivo:** Este notebook tem como objetivo treinar, avaliar e comparar três diferentes algoritmos de classificação para o problema de previsão de churn de clientes da MegaTelCo.\n",
    "\n",
    "Os modelos a serem avaliados são:\n",
    "1.  Regressão Logística (nosso modelo base)\n",
    "2.  Árvore de Decisão\n",
    "3.  Gaussian Naïve Bayes\n",
    "\n",
    "A comparação final será realizada com base em métricas de performance como Acurácia, Precisão, Recall, F1-Score e, principalmente, a AUC (Área Sob a Curva ROC).\n",
    "\n",
    "--------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1fc69",
   "metadata": {},
   "source": [
    "### **Importando as Bibliotecas Necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2297a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Métricas de Avaliação\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "# Configurações visuais\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ace47",
   "metadata": {},
   "source": [
    "### **Carregamento e Preparação dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ede8cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Code\\\\ML\\\\Dados'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mCode\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mDados\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m os.getcwd()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Code\\\\ML\\\\Dados'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Code\\\\ML\\\\Dados')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "retention_train = pd.read_csv('train_deduplicado.csv')\n",
    "retention_test = pd.read_csv('test_deduplicado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b704f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um dicionário para o mapeamento desejado\n",
    "label_map = {\n",
    "    'STAY': 0,\n",
    "    'LEAVE': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplique o mapeamento à sua coluna usando o método .map() do pandas\n",
    "retention_train['leave'] = retention_train['leave'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f77ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplique o mapeamento à sua coluna usando o método .map() do pandas\n",
    "retention_test['leave'] = retention_test['leave'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c7da6",
   "metadata": {},
   "source": [
    "### **Preparação dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af93095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pré-processamento ---\n",
    "\n",
    "# 1. Tratamento de valores faltantes (usando a média do TREINO para ambos)\n",
    "media_preco_treino = retention_train['handset_price'].mean()\n",
    "retention_train['handset_price'] = retention_train['handset_price'].fillna(media_preco_treino)\n",
    "retention_test['handset_price'] = retention_test['handset_price'].fillna(media_preco_treino)\n",
    "\n",
    "# 2. Definindo as features (X) e a variável alvo (y)\n",
    "features = ['income', 'house', 'handset_price', 'overage', 'leftover', 'over_15mins_calls_per_month', 'average_call_duration']\n",
    "target = 'leave'\n",
    "\n",
    "X_train = retention_train[features]\n",
    "y_train = retention_train[target]\n",
    "\n",
    "X_test = retention_test[features]\n",
    "y_test = retention_test[target]\n",
    "\n",
    "# 3. Escalonamento das Features\n",
    "# É uma boa prática para Regressão Logística e Naive Bayes\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos o scaler com os dados de TREINO e transformamos ambos os conjuntos\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dados prontos para o treinamento!\")\n",
    "print(\"Formato de X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Formato de X_test_scaled:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f61574",
   "metadata": {},
   "source": [
    "## **2. Treinando os Classificadores**\n",
    "\n",
    "Agora, vamos instanciar e treinar cada um dos quatro modelos com nossos dados de treino escalonados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os modelos treinados\n",
    "models = {}\n",
    "\n",
    "# --- 1. Regressão Logística (Baseline) ---\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "models['Regressão Logística'] = log_reg\n",
    "print(\"Modelo 'Regressão Logística' treinado.\")\n",
    "\n",
    "# --- 2. Árvore de Decisão ---\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train_scaled, y_train)\n",
    "models['Árvore de Decisão'] = tree_clf\n",
    "print(\"Modelo 'Árvore de Decisão' treinado.\")\n",
    "\n",
    "# --- 3. Gaussian Naïve Bayes ---\n",
    "# Ideal para features contínuas que assumimos ter uma distribuição normal\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "models['Naïve Bayes'] = gnb\n",
    "print(\"Modelo 'Naïve Bayes' treinado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf145ea1",
   "metadata": {},
   "source": [
    "## **3. Comparação de Performance**\n",
    "\n",
    "Com os modelos treinados, o próximo passo é avaliá-los nos dados de teste. Faremos isso de duas formas:\n",
    "1.  **Tabela de Métricas:** Um resumo com as principais métricas de classificação.\n",
    "2.  **Curva ROC:** Uma comparação visual da capacidade de cada modelo em distinguir as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os resultados de cada modelo\n",
    "performance_data = {}\n",
    "\n",
    "# Loop para calcular as métricas de cada modelo\n",
    "for name, model in models.items():\n",
    "    # Fazer previsões nos dados de teste\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Gerar o classification report como um dicionário\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Calcular a AUC\n",
    "    # Para AUC, precisamos da probabilidade da classe positiva (1)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(report)\n",
    "    \n",
    "    # Salvar as métricas de interesse (focando na classe '1', que é o churn)\n",
    "    performance_data[name] = {\n",
    "        'Acurácia': report['accuracy'],\n",
    "        'Precisão (classe 1)': report['1']['precision'],\n",
    "        'Recall (classe 1)': report['1']['recall'],\n",
    "        'F1-Score (classe 1)': report['1']['f1-score'],\n",
    "        'AUC': auc\n",
    "    }\n",
    "\n",
    "# Converter o dicionário em um DataFrame do pandas para melhor visualização\n",
    "performance_df = pd.DataFrame.from_dict(performance_data, orient='index')\n",
    "\n",
    "# Exibindo a tabela de performance ordenada pela AUC (melhor métrica geral)\n",
    "print(\"Tabela Comparativa de Performance dos Modelos:\")\n",
    "display(performance_df.sort_values(by='AUC', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aa8aa",
   "metadata": {},
   "source": [
    "### **Comparação Visual com a Curva ROC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop para plotar a Curva ROC de cada modelo\n",
    "for name, model in models.items():\n",
    "    # Prever as probabilidades\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calcular fpr, tpr e AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Plotar a curva\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "# Plotar a linha de referência (classificador aleatório)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Classificador Aleatório')\n",
    "\n",
    "# Configurações do gráfico\n",
    "plt.title('Comparação da Curva ROC entre os Modelos', fontsize=16)\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)', fontsize=12)\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)', fontsize=12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba628bc",
   "metadata": {},
   "source": [
    "## **4. Conclusão**\n",
    "\n",
    "Ao analisar a tabela de métricas e o gráfico da Curva ROC, podemos tirar algumas conclusões:\n",
    "\n",
    "* **Melhor Modelo Geral (AUC):** O modelo com a maior AUC foi o **[Nome do Modelo com Maior AUC]**. A AUC é uma ótima métrica geral porque avalia a capacidade do modelo de discriminar corretamente entre clientes que sairão e que ficarão, em todos os limiares de probabilidade.\n",
    "\n",
    "* **Melhor em Evitar Falsos Positivos (Precisão):** Se o objetivo da MegaTelCo fosse gastar recursos de retenção apenas com clientes que **com certeza** vão sair (evitando \"incomodar\" clientes fiéis), o modelo com a maior **precisão** para a classe 1 seria o mais indicado. Esse modelo foi o **[Nome do Modelo com Maior Precisão]**.\n",
    "\n",
    "* **Melhor em \"Pegar\" Todos os Churns (Recall):** Se a prioridade fosse identificar o maior número possível de clientes que estão prestes a sair, mesmo que isso signifique incluir alguns alarmes falsos, o modelo com o maior **recall** seria a escolha. Esse modelo foi o **[Nome do Modelo com Maior Recall]**.\n",
    "\n",
    "\n",
    "**Recomendação Final:** Com base nos resultados, o **[Nome do Modelo Vencedor]** parece ser a escolha mais equilibrada e performática para este problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
